{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484b7e7a",
   "metadata": {},
   "source": [
    "# Assignment April 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e4c31",
   "metadata": {},
   "source": [
    "Q1. Purpose and working of grid search cv:\n",
    "\n",
    "Purpose: Grid search cross-validation (GridSearchCV) is used to tune hyperparameters of a machine learning model by exhaustively searching through a specified parameter grid and selecting the combination that yields the best performance.\n",
    "Working: It works by defining a grid of hyperparameter values to explore, then evaluating the model's performance for each combination of hyperparameters using cross-validation. The combination with the best performance is selected as the optimal set of hyperparameters.\n",
    "\n",
    "Q2. Difference between grid search cv and random search cv:\n",
    "\n",
    "Grid search cv: It exhaustively searches through a predefined set of hyperparameters.\n",
    "Random search cv: It randomly samples hyperparameters from a predefined distribution.\n",
    "Choosing one over the other: Grid search cv is suitable when the hyperparameter search space is relatively small and can be exhaustively searched. Random search cv is preferable when the search space is large or when computational resources are limited.\n",
    "\n",
    "Q3. Data leakage and its implications:\n",
    "\n",
    "Definition: Data leakage occurs when information from outside the training dataset is inadvertently used to create the model, leading to overly optimistic performance estimates.\n",
    "Problem: It can result in models that perform well on training and validation data but poorly in real-world scenarios where the leaked information is not available.\n",
    "Example: Including future information (e.g., target variable values that occur after the current time point) in the training data can lead to data leakage.\n",
    "\n",
    "Q4. Preventing data leakage:\n",
    "\n",
    "Strict data partitioning: Ensure that data splitting into training, validation, and test sets is done chronologically or in a way that prevents future information from leaking into the training set.\n",
    "Feature engineering: Be cautious when creating features to avoid using information that would not be available at the time of prediction.\n",
    "\n",
    "Q5. Confusion matrix and its interpretation:\n",
    "\n",
    "Definition: A confusion matrix is a table that summarizes the performance of a classification model by comparing actual and predicted classes.\n",
    "Interpretation: It provides insights into the model's performance in terms of true positives, true negatives, false positives, and false negatives.\n",
    "Q6. Precision and recall:\n",
    "\n",
    "Precision: It measures the proportion of correctly predicted positive instances out of all instances predicted as positive.\n",
    "Recall: It measures the proportion of correctly predicted positive instances out of all actual positive instances.\n",
    "\n",
    "Q7. Interpreting a confusion matrix:\n",
    "\n",
    "Types of errors: By examining the entries of the confusion matrix, you can identify which types of errors the model is making, such as false positives or false negatives.\n",
    "\n",
    "Q8. Common metrics from a confusion matrix:\n",
    "\n",
    "Accuracy: (TP + TN) / (TP + TN + FP + FN)\n",
    "Precision: TP / (TP + FP)\n",
    "Recall: TP / (TP + FN)\n",
    "F1-score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "Q9. Relationship between accuracy and confusion matrix:\n",
    "\n",
    "Accuracy is the overall correctness of the model, calculated as the proportion of correctly classified instances among all instances. It's directly related to the values in the confusion matrix, especially the true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "Q10. Using confusion matrix to identify biases or limitations:\n",
    "\n",
    "By analyzing the confusion matrix, you can identify if the model is biased towards certain classes or if there are patterns in misclassifications. Biases or limitations may indicate areas where the model needs improvement, such as collecting more diverse training data or adjusting class weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
